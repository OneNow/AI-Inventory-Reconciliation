{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Val List is', 36032)\n",
      "('Train List is', 324734)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "train_file = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/counting_train.json'\n",
    "val_file = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/counting_val.json'\n",
    "\n",
    "train_file_new = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_train_new.json'\n",
    "val_file_new = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_val_new.json'\n",
    "test_file_new = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_test_new.json'\n",
    "\n",
    "with open(train_file) as f:\n",
    "          train_list = json.loads(f.read())\n",
    "\n",
    "with open(val_file) as f:\n",
    "          val_list = json.loads(f.read())\n",
    "          \n",
    "print(\"Val List is\", len(val_list))\n",
    "print(\"Train List is\", len(train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom data last minute\n",
    "random.Random(5).shuffle(train_list)\n",
    "train_list_final = train_list[0:288734]\n",
    "test_list_final = train_list[288734:324734]\n",
    "val_list_final = val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_final = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_train_final.json'\n",
    "val_file_final = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_val_final.json'\n",
    "test_file_final = '/home/ubuntu/efs/amazon-bin/code/workspace/sravan-dl/input/counting_test_final.json'\n",
    "\n",
    "with open(train_file_final,'wb') as f1:\n",
    "        json.dump(train_list_final,f1)\n",
    "        \n",
    "with open(val_file_final,'wb') as f2:\n",
    "        json.dump(val_list_final,f2)\n",
    "        \n",
    "with open(test_file_final,'wb') as f3:\n",
    "        json.dump(test_list_final,f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('len data is', 156152)\n",
      "('len train', 109306)\n",
      "('len val', 31230)\n",
      "('len test', 15616)\n"
     ]
    }
   ],
   "source": [
    "# consolidate val and train into a single list\n",
    "# 156152\n",
    "#train 109306\n",
    "#val 31230\n",
    "# test 15616\n",
    "data = []\n",
    "for item in train_list:\n",
    "    data.append(item)\n",
    "\n",
    "for item in val_list:\n",
    "    data.append(item)\n",
    "    \n",
    "print(\"len data is\", len(data))\n",
    "\n",
    "# Prepare training\n",
    "random.Random(5).shuffle(data)\n",
    "train_list_new = data[0:109306]\n",
    "val_list_new = data[109306:140536]\n",
    "test_list_new = data[140536:156152]\n",
    "\n",
    "print(\"len train\", len(train_list_new))\n",
    "print(\"len val\", len(val_list_new))\n",
    "print(\"len test\", len(test_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all the files to input folder\n",
    "\n",
    "with open(train_file_new,'wb') as f1:\n",
    "        json.dump(train_list_new,f1)\n",
    "        \n",
    "with open(val_file_new,'wb') as f2:\n",
    "        json.dump(val_list_new,f2)\n",
    "        \n",
    "with open(test_file_new,'wb') as f3:\n",
    "        json.dump(test_list_new,f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Checking distribution of training data\n",
    "train_np = np.zeros(6,)\n",
    "val_np = np.zeros(6,)\n",
    "test_np = np.zeros(6,)\n",
    "\n",
    "for item in train_list_new:\n",
    "    train_np[item[1]] = train_np[item[1]] + 1\n",
    "    \n",
    "for item in test_list_new:\n",
    "    test_np[item[1]] = test_np[item[1]] + 1\n",
    "    \n",
    "for item in val_list_new:\n",
    "    val_np[item[1]] = val_np[item[1]] + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2936. 12560. 23321. 27073. 24452. 18964.]\n",
      "[ 433. 1748. 3374. 3938. 3464. 2659.]\n",
      "[ 907. 3641. 6635. 7912. 6849. 5286.]\n"
     ]
    }
   ],
   "source": [
    "print(train_np)\n",
    "print(test_np)\n",
    "print(val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
